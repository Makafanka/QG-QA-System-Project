# -*- coding: utf-8 -*-
"""NLP Project QA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v3IIAa8Qfikj7BQmhblRQUGdImVnhqyv

# Data Preprocessing

## Import data
"""

import numpy as np
import csv
import json
import pandas as pd
# Loading the training and testing dataset. We will need to format them to be
# suited to the model.

train_df = pd.read_csv('/content/drive/MyDrive/NLP data source/Tweet Sentiment Extraction/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/NLP data source/Tweet Sentiment Extraction/test.csv')

train = np.array(train_df)
test = np.array(test_df)

!mkdir -p data

use_cuda = True

from google.colab import drive
drive.mount('/content/drive')

# Install the simple transformer tool
!pip install '/content/drive/MyDrive/NLP data source/Simple transformers PyPI/seqeval-0.0.12-py3-none-any.whl' -q
!pip install '/content/drive/MyDrive/NLP data source/Simple transformers PyPI/simpletransformers-0.22.1-py3-none-any.whl' -q

train_df.head()

"""## Preprocess training dataset"""

# helper function to find all the indices where the specific answer
# appears in the text.
def find_all(input_str, search_str):
    l1 = []
    length = len(input_str)
    index = 0
    while index < length:
        i = input_str.find(search_str, index)
        if i == -1:
            return l1
        l1.append(i)
        index = i + 1
    return l1
# preprocess the training dataset such that we know, for each input article text,
# all the places where the answer appears.
def do_qa_train(train):
    output = []
    for line in train:
        context = line[1]

        qas = []
        question = line[-1]
        qid = line[0]
        answers = []
        answer = line[2]
        if type(answer) != str or type(context) != str or type(question) != str:
            print(context, type(context))
            print(answer, type(answer))
            print(question, type(question))
            continue
        answer_starts = find_all(context, answer)
        for answer_start in answer_starts:
            answers.append({'answer_start': answer_start, 'text': answer.lower()})
            break
        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})
        output.append({'context': context.lower(), 'qas': qas})
    return output

qa_train = do_qa_train(train)

with open('/content/data/train.json', 'w+') as outfile:
    json.dump(qa_train, outfile)

"""##Preprocess test dataset"""

# preprocess the testing file; adjust the format
def do_qa_test(test):
    output = []
    for line in test:
        context = line[1]
        qas = []
        question = line[-1]
        qid = line[0]
        if type(context) != str or type(question) != str:
            print(context, type(context))
            print(answer, type(answer))
            print(question, type(question))
            continue
        answers = []
        answers.append({'answer_start': 1000000, 'text': '__None__'})
        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})
        output.append({'context': context.lower(), 'qas': qas})
    return output

qa_test = do_qa_test(test)

with open('data/test.json', 'w+') as outfile:
    json.dump(qa_test, outfile)

"""# Model Setup

replicate GNN from paper
"""



"""# Model training and testing"""

# Commented out IPython magic to ensure Python compatibility.
# MODEL_PATH = '/content/drive/MyDrive/NLP data source/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad/'
# # Create the QuestionAnsweringModel
# model = QuestionAnsweringModel('distilbert',
#                                MODEL_PATH,
#                                args={'reprocess_input_data': True,
#                                      'overwrite_output_dir': True,
#                                      'learning_rate': 5e-5,
#                                      'num_train_epochs': 3,
#                                      'max_seq_length': 192,
#                                      'doc_stride': 64,
#                                      'fp16': False,
#                                     },
#                               use_cuda=use_cuda)
# 
# model.train_model('data/train.json')
# 
# %%time
# 
# predictions = model.predict(qa_test)
# predictions_df = pd.DataFrame.from_dict(predictions)
# 
# sub_df['selected_text'] = predictions_df['answer']
# 
# sub_df.to_csv('submission.csv', index=False)
# 
# print("File submitted successfully.")

"""# Model evaluation and analysis"""