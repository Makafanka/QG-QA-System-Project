# -*- coding: utf-8 -*-
"""QG_transformer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yk35qmWkFpGiD74LJT7QyL7WnZwvzmc1

# Setting Up Environment
"""

!pip install -q condacolab
import condacolab
condacolab.install()
!conda --version

!conda create -n simpletransformers python pandas tqdm
!conda activate simpletransformers
!conda install pytorch cudatoolkit=11.2 -c pytorch
!pip install simpletransformers
!pip install datasets

import logging
import pandas as pd
from sklearn.model_selection import train_test_split
# from simpletransformers.t5 import T5Model, T5Args

logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

from datasets import load_dataset
squad = load_dataset("squad")

import torch
# print(torch.cuda.is_available())

"""# Processing Data"""

def squad2df(type="train"):

    input_data = squad[type]

    prefix_list = []
    input_text_list = []
    target_text_list = []

    i = 0
    for entry in input_data:
        prefix_list.append("question generation")
        input_text_list.append(entry["context"])
        target_text_list.append(entry["question"])

        i += 1
        # if i == 20: break

    output_df = pd.DataFrame(
        {
            "prefix": prefix_list,
            "input_text": input_text_list,
            "target_text": target_text_list,
        }
    )

    return output_df

def reformat_data(file="qa_dataset-0.1.csv", doc_path="documents"):
    df = pd.read_csv(file)

    input_text_list = []
    target_text_list = []

    i = 0
    for id in df["document_id"]:
        with open(doc_path + id, 'r') as doc:
            data = doc.read().replace('\n', '')
        input_text_list.append(data)

        i += 1
        # if i == 10: break

    output_df = pd.DataFrame(
        {
            "prefix": "question generation",
            "input_text": input_text_list,
            "target_text": df["question"][:10],
        }
    )

    return output_df

"""# Training Model"""

def count_matches(labels, preds):
    print(labels)
    print(preds)
    return sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])

if __name__ == "__main__":

    squad_train = squad2df("train")
    squad_eval = squad2df("validation")

    canvas_df = reformat_data(file="qa_dataset-0.1.csv", doc_path="documents")
    canvas_train, canvas_eval = train_test_split(canvas_df, test_size=0.05)

    model_args = {
    "reprocess_input_data": True,
    "overwrite_output_dir": True,
    "max_seq_length": 128,
    "train_batch_size": 8,
    "num_train_epochs": 100,
    "save_eval_checkpoints": True,
    "save_steps": -1,
    "use_multiprocessing": False,
    "evaluate_during_training": True,
    "evaluate_during_training_steps": 15000,
    "evaluate_during_training_verbose": True,
    "evaluate_generated_text": True,
    "fp16": False,
    }

    use_cuda = torch.cuda.is_available()
    model = T5Model("t5", "t5-base", args=model_args, use_cuda=use_cuda)

    model.train_model(canvas_train, eval_data=canvas_eval, matches=count_matches)

    print(model.eval_model(canvas_eval, matches=count_matches))

"""# Generating Questions"""

from simpletransformers.t5 import T5Model
import pandas as pd
from pprint import pprint


model_args = {
    "reprocess_input_data": True,
    "overwrite_output_dir": True,
    "max_seq_length": 128,
    "eval_batch_size": 128,
    "num_train_epochs": 1,
    "save_eval_checkpoints": False,
    "use_multiprocessing": False,
    "num_beams": None,
    "do_sample": True,
    "max_length": 50,
    "top_k": 50,
    "top_p": 0.95,
    "num_return_sequences": 3,
}

model = T5Model("test_outputs_large/best_model", args=model_args)

df = pd.read_csv("data/eval_df.tsv", sep="\t").astype(str)
preds = model.predict(
    ["ask_question: " + description for description in df["input_text"].tolist()]
)

questions = df["target_text"].tolist()

with open("test_outputs_large/generated_questions_sampling.txt", "w") as f:
    for i, desc in enumerate(df["input_text"].tolist()):
        pprint(desc)
        pprint(preds[i])
        print()

        f.write(str(desc) + "\n\n")

        f.write("Real question:\n")
        f.write(questions[i] + "\n\n")

        f.write("Generated questions:\n")
        for pred in preds[i]:
            f.write(str(pred) + "\n")
        f.write("________________________________________________________________________________\n")